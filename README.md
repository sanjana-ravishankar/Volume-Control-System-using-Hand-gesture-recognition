The project focused on making a robust hand gesture recognition system to control the volume of the system without having to touch the screen manually or use the keyboard or mouse. The system proved useful to the aged/visually impaired people who cannot control the system volume with ease and can use their hand gestures rather, to control the volume level.

The hand gestures are first captured by the system's in-built webcam and the gestures are processed into a graph with various points of our hand as different indices. These indices can later be mapped through formulae based on Python's math libraries which operate on intricate algorithms to either increase or decrease the volume levels, based on the hand movements. The percentage level can be seen changing side - by - side as the gestures change.
